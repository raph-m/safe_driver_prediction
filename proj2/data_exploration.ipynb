{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "from subprocess import check_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = \"/media/raph/Elements/ml1/churn/\"\n",
    "nrows_for_members = None\n",
    "nrows_for_transactions = 100\n",
    "nrows_for_train = None\n",
    "nrows_for_train_v2 = None\n",
    "nrows_for_transactions = None\n",
    "nrows_for_transactions_v2 = 1000000\n",
    "nrows_for_test = None\n",
    "nrows_for_test_v2 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(path_to_data+\"train_v2.csv\", nrows=nrows_for_train_v2)\n",
    "train = pd.concat((train, pd.read_csv(path_to_data+\"train.csv\", nrows=nrows_for_train)), axis=0, ignore_index=True).reset_index(drop=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "members = pd.read_csv(path_to_data + \"members_v3.csv\", nrows=nrows_for_members)\n",
    "members.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "members.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.merge(left = train,right = members,how = 'left',on=['msno'])\n",
    "\n",
    "# changing type to int and putting -1 for missing values\n",
    "training['city'] = training.city.apply(lambda x: int(x) if pd.notnull(x) else -1)\n",
    "training['registered_via'] = training.registered_via.apply(lambda x: int(x) if pd.notnull(x) else -1)\n",
    "training['bd'] = training.bd.apply(lambda x: int(x) if pd.notnull(x) else -1)\n",
    "training['bd'] = training.bd.apply(lambda x: x if (10<x<100) else -1)\n",
    "\n",
    "genders_encoding = {'male': 0, 'female': 1}\n",
    "training['gender'] = training.gender.apply(lambda x: genders_encoding[x] if pd.notnull(x) else -1)\n",
    "\n",
    "# changing date formats\n",
    "training['registration_init_time'] = training.registration_init_time.apply(lambda x: datetime.strptime(str(int(x)), \"%Y%m%d\").date() if pd.notnull(x) else \"NAN\")\n",
    "training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train\n",
    "del members\n",
    "\n",
    "from tools import change_datatype, change_datatype_float\n",
    "# reducing memory usage:\n",
    "change_datatype(training)\n",
    "change_datatype_float(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets make a short explanation here.\n",
    "We can see that we have a train dataset with 970m entries. And the members dataset has 6M entries. So we actually have a huge number of members and the train dataset is giving us a list of users with the description of whether they churned or not. The test dataset will give us another set of users asking us which will churn during the next month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#registration_init_time yearly trend\n",
    "training['registration_init_time_year'] = pd.DatetimeIndex(training['registration_init_time']).year\n",
    "training['registration_init_time_year'] = training.registration_init_time_year.apply(lambda x: int(x) if pd.notnull(x) else \"NAN\" )\n",
    "year_count=training['registration_init_time_year'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.subplot(311)\n",
    "year_order = training['registration_init_time_year'].unique()\n",
    "year_order=sorted(year_order, key=lambda x: str(x))\n",
    "year_order = sorted(year_order, key=lambda x: float(x))\n",
    "sns.barplot(year_count.index, year_count.values,order=year_order)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.xlabel('Year', fontsize=12)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.title(\"Yearly Trend of registration_init_time\", fontsize=12)\n",
    "plt.show()\n",
    "year_count_2 = Counter(training['registration_init_time_year']).most_common();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets see how the year of registration influences the probability of churn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_mean_on_year = []\n",
    "for y in year_order:\n",
    "    current = training.loc[training['registration_init_time_year']==y]['is_churn'].mean()\n",
    "    churn_mean_on_year.append(current)\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.subplot(311)\n",
    "sns.barplot(year_order, churn_mean_on_year,order=year_order)\n",
    "plt.ylabel('Churning ratio', fontsize=12)\n",
    "plt.xlabel('Year', fontsize=12)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.title(\"Churning ratio vs registration_init_time\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gender count\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.subplot(413)\n",
    "sns.countplot(x=\"gender\", data=training)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.xlabel('Gender', fontsize=12)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.title(\"Gender Count\", fontsize=12)\n",
    "plt.show()\n",
    "gender_count = Counter(training['gender']).most_common()\n",
    "\n",
    "genders = []\n",
    "churn_mean_on_gender = []\n",
    "for (g, _) in gender_count:\n",
    "    genders.append(g)\n",
    "    churn_mean_on_gender.append(training.loc[training['gender']==g]['is_churn'].mean())\n",
    "\n",
    "plt.figure(figsize=(12,12)) \n",
    "plt.subplot(413)\n",
    "sns.barplot(genders, churn_mean_on_gender, genders)\n",
    "plt.ylabel('Churning ratio', fontsize=12)\n",
    "plt.xlabel('Gender', fontsize=12)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.title(\"Churning ratio vs gender\", fontsize=12)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# City count in Members Data Set\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.subplot(311)\n",
    "sns.countplot(x=\"city\", data=training)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.xlabel('City', fontsize=12)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.title(\"City count in Training dataset\", fontsize=12)\n",
    "plt.show()\n",
    "city_count = Counter(training['city']).most_common()\n",
    "\n",
    "#Registered Via Count in Members Data Set\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.subplot(312)\n",
    "sns.countplot(x=\"registered_via\", data=training)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.xlabel('Registered Via', fontsize=12)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.title(\"Registered Via Count in Training Data Set\", fontsize=12)\n",
    "plt.show()\n",
    "RV_count = Counter(training['registered_via']).most_common();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_mean_on_city = []\n",
    "cities = []\n",
    "for (city, count) in city_count:\n",
    "    if count > 1000:\n",
    "        current = training.loc[training['city']==city]['is_churn'].mean()\n",
    "        churn_mean_on_city.append(current)\n",
    "        cities.append(city)\n",
    "        \n",
    "plt.figure(figsize=(12,12)) \n",
    "plt.subplot(413)\n",
    "sns.barplot(cities, churn_mean_on_city)\n",
    "plt.ylabel('Churning ratio', fontsize=12)\n",
    "plt.xlabel('City', fontsize=12)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.title(\"Churning ratio vs city\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_mean_on_rv = []\n",
    "rv = []\n",
    "for (source, count) in RV_count:\n",
    "    if count > 1000:\n",
    "        current = training.loc[training['registered_via']==source]['is_churn'].mean()\n",
    "        churn_mean_on_rv.append(current)\n",
    "        rv.append(source)\n",
    "        \n",
    "plt.figure(figsize=(12,12)) \n",
    "plt.subplot(413)\n",
    "sns.barplot(rv, churn_mean_on_rv)\n",
    "plt.ylabel('Churning ratio', fontsize=12)\n",
    "plt.xlabel('Registered via', fontsize=12)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.title(\"Churning ratio vs Registered via \", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try to fit a simple model to this first set of data and see what kind of results we get ! (this will enable us to have a reference for any other models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "training['registration_init_time'] = training.registration_init_time.apply(lambda x: time.mktime(x.timetuple()) if not type(x)==type('str') else 0.0)\n",
    "training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = training.iloc[:, [2, 3, 4, 5, 6]].values\n",
    "y = training.iloc[:, 1].values\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "print(\"fitting model...\")\n",
    "# Fitting Random Forest Classification to the Training set\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "print(\"predicting...\")\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict_proba(X_test)[:, 1]\n",
    "y_pred_train = classifier.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm_train = confusion_matrix(y_train, y_pred_train>0.5)\n",
    "print(\"\\nconfusion matrix on train: \")\n",
    "print(cm_train)\n",
    "cm_test = confusion_matrix(y_test, y_pred>0.5)\n",
    "print(\"\\nconfusion matrix on test: \")\n",
    "print(cm_test)\n",
    "\n",
    "from tools import log_loss\n",
    "print(\"\\nloss on train: \")\n",
    "print(log_loss(y_train, y_pred_train))\n",
    "print(\"\\nloss on test: \")\n",
    "print(log_loss(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now lets explore the transactions dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = pd.read_csv(path_to_data+\"transactions.csv\", nrows=nrows_for_transactions)\n",
    "transactions = pd.concat((transactions, pd.read_csv(path_to_data+\"transactions_v2.csv\", nrows=nrows_for_transactions_v2)), axis=0, ignore_index=True).reset_index(drop=True)\n",
    "transactions['transaction_date'] = transactions.transaction_date.apply(lambda x: datetime.strptime(str(int(x)), \"%Y%m%d\").date() if pd.notnull(x) else \"NAN\")\n",
    "transactions['membership_expire_date'] = transactions.membership_expire_date.apply(lambda x: datetime.strptime(str(int(x)), \"%Y%m%d\").date() if pd.notnull(x) else \"NAN\")\n",
    "transactions['payment_method_id'] = transactions.payment_method_id.apply(lambda x: int(x) if pd.notnull(x) else -1)\n",
    "transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_datatype(transactions)\n",
    "change_datatype_float(transactions)\n",
    "transactions.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"computing\")\n",
    "user_count = Counter(transactions['msno']).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hello\")\n",
    "training[\"number_of_transactions\"] = 0\n",
    "training.set_index('msno', inplace=True)\n",
    "training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = []\n",
    "i = 0\n",
    "print(\"helo\")\n",
    "for id_, count in user_count:\n",
    "    counts.append(count)\n",
    "    if i % 100000 == 0:\n",
    "        print(i)\n",
    "    i+=1\n",
    "    try:\n",
    "        training['number_of_transactions'].loc[id_] = count\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "bins = range(1, 5)\n",
    "\n",
    "sns.distplot(counts[5000:],kde=False, norm_hist=True, bins=bins)\n",
    "plt.ylabel('Percentage', fontsize=12)\n",
    "plt.xlabel('Number of transactions', fontsize=12)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.title(\"Number of transactions for the same user\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets comment this plot:\n",
    "So there is in most cases a single transaction in the dataset for each user. This means that it might not be very helpful to look at the evolution of transactions for a user. What we might want to do is to keep only one transaction for each user and we are going to keep only the earliest transaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of transactions vs churn ratio\n",
    "i = 0\n",
    "churn_elements = np.array([0, 0, 0, 0])\n",
    "total_elements = np.array([0, 0, 0, 0])\n",
    "i = 0\n",
    "\n",
    "for element in training.itertuples():\n",
    "    if i % 100000 == 0:\n",
    "        print(i)\n",
    "    i+=1\n",
    "    if element.number_of_transactions < 4:\n",
    "        total_elements[element.number_of_transactions] += 1\n",
    "        if element.is_churn:\n",
    "            churn_elements[element.number_of_transactions] += 1\n",
    "\n",
    "print(churn_elements)\n",
    "print(total_elements)\n",
    "\n",
    "for i in range (len(churn_elements)):\n",
    "    churn_elements[i] /= total_elements[i]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "transactions['transaction_date_month'] = pd.DatetimeIndex(transactions['transaction_date']).month\n",
    "transactions['transaction_date_month'] = transactions.transaction_date_month.apply(lambda x: int(x) if pd.notnull(x) else -1)\n",
    "month_count=transactions['transaction_date_month'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "month_order = transactions['transaction_date_month'].unique()\n",
    "month_order=sorted(month_order, key=lambda x: str(x))\n",
    "month_order = sorted(month_order, key=lambda x: float(x))\n",
    "sns.barplot(month_count.index, month_count.values,order=month_order)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.xlabel('Month', fontsize=12)\n",
    "plt.title(\"Monthly Trend of transaction_date_month\", fontsize=12)\n",
    "plt.show()\n",
    "year_count_2 = Counter(transactions['transaction_date_month']).most_common();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions['membership_expire_date_month'] = pd.DatetimeIndex(transactions['membership_expire_date']).month\n",
    "transactions['membership_expire_date_month'] = transactions.membership_expire_date_month.apply(lambda x: int(x) if pd.notnull(x) else -1)\n",
    "month_count=transactions['membership_expire_date_month'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "month_order = transactions['membership_expire_date_month'].unique()\n",
    "month_order=sorted(month_order, key=lambda x: str(x))\n",
    "month_order = sorted(month_order, key=lambda x: float(x))\n",
    "sns.barplot(month_count.index, month_count.values,order=month_order)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.xlabel('Month', fontsize=12)\n",
    "plt.title(\"Monthly Trend of membership_expire_date_month\", fontsize=12)\n",
    "plt.show()\n",
    "year_count_2 = Counter(transactions['membership_expire_date_month']).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversion en set augmente la vitesse de façon PHENOMENALE\n",
    "id_set = set(training['msno'].values)\n",
    "bins = np.array([1 if id_ in id_set else 0 for id_ in transactions['msno']])\n",
    "# quel pourcentage des transactions fait partie du training ?\n",
    "print(np.mean(bins))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Il est temps de loader la base de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(path_to_data+\"sample_submission_v2.csv\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_set = set(test['msno'].values)\n",
    "bins = np.array([1 if id_ in id_set else 0 for id_ in transactions['msno']])\n",
    "# quel pourcentage des transactions fait partie du test ?\n",
    "print(np.mean(bins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_set = set(training['msno'].values)\n",
    "bins = np.array([1 if id_ in id_set else 0 for id_ in test['msno']])\n",
    "# quel pourcentage des données de test sont dans le fichier de train ?\n",
    "print(np.mean(bins))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donc 88% des données de test sont dans le fichier de train. C'est très bizarre du coup. Mais bon comme on essaye de prédire un évènement nouveau ça peut avoir du sens. Ce que je comprends pas c'est surtout pourquoi il y a si peu de transactions... En moyenne les gens reprennent l'abonnement pour deux mois donc ça peut expliquer qu'il y ait moins de transactions.\n",
    "\n",
    "un kernel pas mal:\n",
    "https://www.kaggle.com/the1owl/regressing-during-insomnia-0-21496\n",
    "Il fait un apprentissage assez bourin et il arrive à un score pas trop mal. Ce qui est intéressant c'est surtout les features qu'il utilise.\n",
    "\n",
    "Un autre kernel qui fait un peu de memory reduction ce qui pourrait faire du bien:\n",
    "https://www.kaggle.com/jeru666/did-you-think-of-these-features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
